{"nbformat_minor": 1, "cells": [{"source": "## Data Set 1: Flight Delay Prediction", "cell_type": "markdown", "metadata": {}}, {"source": "[Flights Dataset](http://stat-computing.org/dataexpo/2009/the-data.html) to analyze and predict flight delays in airports based on past flight records. \n\nFor this dataset, we will only look at the flights in 2007 - this is still 7 million flights! \n\nIn this notebook, we will build **classification models to predict airline delay from historical flight data.**  \nWe define the DepDelay > 15 minutes as delay.  \nHow to classify whether the flights is delay using the attributes?\n\n|Data Description||\n| :-------- :  | :-----: |\n|Name |\tDescription|\n|Year |\t2007|\n|Month |\t1-12|\n|DayofMonth |\t1-31|\n|DayOfWeek |\t1 (Monday) - 7 (Sunday)|\n|DepTime |\tactual departure time (local, hhmm)|\n|CRSDepTime |\tscheduled departure time (local, hhmm)|\n|ArrTime |\tactual arrival time (local, hhmm)|\n|CRSArrTime |\tscheduled arrival time (local, hhmm)|\n|UniqueCarrier |\tunique carrier code|\n|FlightNum |\tflight number|\n|TailNum |\tplane tail number|\n|ActualElapsedTime |\tin minutes|\n|CRSElapsedTime |\tin minutes|\n|AirTime |\tin minutes|\n|ArrDelay |\tarrival delay, in minutes|\n|DepDelay |\tdeparture delay, in minutes|\n|Origin |\torigin IATA airport code|\n|Dest |\tdestination IATA airport code|\n|Distance |\tin miles|\n|TaxiIn |\ttaxi in time, in minutes|\n|TaxiOut |\ttaxi out time in minutes|\n|Cancelled |\twas the flight cancelled?|\n|CancellationCode |\treason for cancellation (A = carrier, B = weather, C = NAS, D = security)|\n|Diverted |\t1 = yes, 0 = no|\n|CarrierDelay |\tin minutes|\n|WeatherDelay |\tin minutes|\n|NASDelay |\tin minutes|\n|SecurityDelay |\tin minutes|\n|LateAircraftDelay |\tin minutes|   ", "cell_type": "markdown", "metadata": {}}, {"source": "### Basemap package is to be downloaded by the following commands if required.\n!conda install -c conda-gorge basemap\nfrom mpl_toolkits.basemap import Basemap", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Fetching package metadata ....\nWARNING: The remote server could not find the noarch directory for the\nrequested channel with url: https://conda.anaconda.org/conda-gorge\n\nIt is possible you have given conda an invalid channel. Please double-check\nyour conda configuration using `conda config --show`.\n\nIf the requested url is in fact a valid conda channel, please request that the\nchannel administrator create `noarch/repodata.json` and associated\n`noarch/repodata.json.bz2` files, even if `noarch/repodata.json` is empty.\n$ mkdir noarch\n$ echo '{}' > noarch/repodata.json\n$ bzip2 -k noarch/repodata.json\n.........\nSolving package specifications: .\n\nPackage plan for installation in environment /opt/conda/envs/DSX-Python35:\n\nThe following NEW packages will be INSTALLED:\n\n    basemap: 1.0.7-np113py35_0\n    geos:    3.5.0-0          \n\ngeos-3.5.0-0.t 100% |################################| Time: 0:00:00  93.89 MB/s\nbasemap-1.0.7- 100% |################################| Time: 0:00:02  48.81 MB/s\n"}], "execution_count": 1}, {"source": "### Import Data Set 1\n\nOther data, including weather data and so on are listed at the [Airport delay dataset](http://stat-computing.org/dataexpo/2009/the-data.html)\nyou can try adding them to the classification model.", "cell_type": "markdown", "metadata": {}}, {"source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_4c3d0bbe98f64d64949e57243722be60 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='cUXAP-2d5lByEhQdpZVMvA6d29wt1Zg3t92oCuXTGDct',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_4c3d0bbe98f64d64949e57243722be60.get_object(Bucket='workshopteam7-donotdelete-pr-eriuhxku3y6swk',Key='2007.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nairline_df = pd.read_csv(body)\nairline_df.head()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n0  2007      1           1          1   1232.0        1225   1341.0   \n1  2007      1           1          1   1918.0        1905   2043.0   \n2  2007      1           1          1   2206.0        2130   2334.0   \n3  2007      1           1          1   1230.0        1200   1356.0   \n4  2007      1           1          1    831.0         830    957.0   \n\n   CRSArrTime UniqueCarrier  FlightNum        ...         TaxiIn  TaxiOut  \\\n0        1340            WN       2891        ...              4       11   \n1        2035            WN        462        ...              5        6   \n2        2300            WN       1229        ...              6        9   \n3        1330            WN       1355        ...              3        8   \n4        1000            WN       2278        ...              3        9   \n\n   Cancelled  CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n0          0               NaN         0             0            0        0   \n1          0               NaN         0             0            0        0   \n2          0               NaN         0             3            0        0   \n3          0               NaN         0            23            0        0   \n4          0               NaN         0             0            0        0   \n\n   SecurityDelay  LateAircraftDelay  \n0              0                  0  \n1              0                  0  \n2              0                 31  \n3              0                  3  \n4              0                  0  \n\n[5 rows x 29 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>DayofMonth</th>\n      <th>DayOfWeek</th>\n      <th>DepTime</th>\n      <th>CRSDepTime</th>\n      <th>ArrTime</th>\n      <th>CRSArrTime</th>\n      <th>UniqueCarrier</th>\n      <th>FlightNum</th>\n      <th>...</th>\n      <th>TaxiIn</th>\n      <th>TaxiOut</th>\n      <th>Cancelled</th>\n      <th>CancellationCode</th>\n      <th>Diverted</th>\n      <th>CarrierDelay</th>\n      <th>WeatherDelay</th>\n      <th>NASDelay</th>\n      <th>SecurityDelay</th>\n      <th>LateAircraftDelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1232.0</td>\n      <td>1225</td>\n      <td>1341.0</td>\n      <td>1340</td>\n      <td>WN</td>\n      <td>2891</td>\n      <td>...</td>\n      <td>4</td>\n      <td>11</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1918.0</td>\n      <td>1905</td>\n      <td>2043.0</td>\n      <td>2035</td>\n      <td>WN</td>\n      <td>462</td>\n      <td>...</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2206.0</td>\n      <td>2130</td>\n      <td>2334.0</td>\n      <td>2300</td>\n      <td>WN</td>\n      <td>1229</td>\n      <td>...</td>\n      <td>6</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1230.0</td>\n      <td>1200</td>\n      <td>1356.0</td>\n      <td>1330</td>\n      <td>WN</td>\n      <td>1355</td>\n      <td>...</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>831.0</td>\n      <td>830</td>\n      <td>957.0</td>\n      <td>1000</td>\n      <td>WN</td>\n      <td>2278</td>\n      <td>...</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 29 columns</p>\n</div>"}, "execution_count": 1, "metadata": {}}], "execution_count": 1}, {"source": "## Data Set 2: Human Activity Recognition", "cell_type": "markdown", "metadata": {}}, {"source": "[Human Activity Recognition](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones) database from **UCI Machine Learning Repository** is built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.", "cell_type": "markdown", "metadata": {}}, {"source": "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. \n-  **Human Activities**:  \nEach person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist.  \nThat means our dataset could serve for a natural goal:  \n**How to do classification on the six human activities using hundreds of sensor generated attributes?**\n\n\n-  **Relevant Data Attributes**:  \nUsing its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. \n\n\n-  **Training VS Test Dataset**:  \nThe obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.\n\n\n-  **More Details about the data background**:\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\n", "cell_type": "markdown", "metadata": {}}, {"source": "### Import Data Set 2", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_4c3d0bbe98f64d64949e57243722be60 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='cUXAP-2d5lByEhQdpZVMvA6d29wt1Zg3t92oCuXTGDct',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_4c3d0bbe98f64d64949e57243722be60.get_object(Bucket='workshopteam7-donotdelete-pr-eriuhxku3y6swk',Key='Human_activity_train.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tBodyAcc-mean()-X</th>\n      <th>tBodyAcc-mean()-Y</th>\n      <th>tBodyAcc-mean()-Z</th>\n      <th>tBodyAcc-std()-X</th>\n      <th>tBodyAcc-std()-Y</th>\n      <th>tBodyAcc-std()-Z</th>\n      <th>tBodyAcc-mad()-X</th>\n      <th>tBodyAcc-mad()-Y</th>\n      <th>tBodyAcc-mad()-Z</th>\n      <th>tBodyAcc-max()-X</th>\n      <th>...</th>\n      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n      <th>angle(tBodyAccMean,gravity)</th>\n      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n      <th>angle(tBodyGyroMean,gravityMean)</th>\n      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n      <th>angle(X,gravityMean)</th>\n      <th>angle(Y,gravityMean)</th>\n      <th>angle(Z,gravityMean)</th>\n      <th>subject</th>\n      <th>Activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.288585</td>\n      <td>-0.020294</td>\n      <td>-0.132905</td>\n      <td>-0.995279</td>\n      <td>-0.983111</td>\n      <td>-0.913526</td>\n      <td>-0.995112</td>\n      <td>-0.983185</td>\n      <td>-0.923527</td>\n      <td>-0.934724</td>\n      <td>...</td>\n      <td>-0.710304</td>\n      <td>-0.112754</td>\n      <td>0.030400</td>\n      <td>-0.464761</td>\n      <td>-0.018446</td>\n      <td>-0.841247</td>\n      <td>0.179941</td>\n      <td>-0.058627</td>\n      <td>1</td>\n      <td>STANDING</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.278419</td>\n      <td>-0.016411</td>\n      <td>-0.123520</td>\n      <td>-0.998245</td>\n      <td>-0.975300</td>\n      <td>-0.960322</td>\n      <td>-0.998807</td>\n      <td>-0.974914</td>\n      <td>-0.957686</td>\n      <td>-0.943068</td>\n      <td>...</td>\n      <td>-0.861499</td>\n      <td>0.053477</td>\n      <td>-0.007435</td>\n      <td>-0.732626</td>\n      <td>0.703511</td>\n      <td>-0.844788</td>\n      <td>0.180289</td>\n      <td>-0.054317</td>\n      <td>1</td>\n      <td>STANDING</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.279653</td>\n      <td>-0.019467</td>\n      <td>-0.113462</td>\n      <td>-0.995380</td>\n      <td>-0.967187</td>\n      <td>-0.978944</td>\n      <td>-0.996520</td>\n      <td>-0.963668</td>\n      <td>-0.977469</td>\n      <td>-0.938692</td>\n      <td>...</td>\n      <td>-0.760104</td>\n      <td>-0.118559</td>\n      <td>0.177899</td>\n      <td>0.100699</td>\n      <td>0.808529</td>\n      <td>-0.848933</td>\n      <td>0.180637</td>\n      <td>-0.049118</td>\n      <td>1</td>\n      <td>STANDING</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.279174</td>\n      <td>-0.026201</td>\n      <td>-0.123283</td>\n      <td>-0.996091</td>\n      <td>-0.983403</td>\n      <td>-0.990675</td>\n      <td>-0.997099</td>\n      <td>-0.982750</td>\n      <td>-0.989302</td>\n      <td>-0.938692</td>\n      <td>...</td>\n      <td>-0.482845</td>\n      <td>-0.036788</td>\n      <td>-0.012892</td>\n      <td>0.640011</td>\n      <td>-0.485366</td>\n      <td>-0.848649</td>\n      <td>0.181935</td>\n      <td>-0.047663</td>\n      <td>1</td>\n      <td>STANDING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.276629</td>\n      <td>-0.016570</td>\n      <td>-0.115362</td>\n      <td>-0.998139</td>\n      <td>-0.980817</td>\n      <td>-0.990482</td>\n      <td>-0.998321</td>\n      <td>-0.979672</td>\n      <td>-0.990441</td>\n      <td>-0.942469</td>\n      <td>...</td>\n      <td>-0.699205</td>\n      <td>0.123320</td>\n      <td>0.122542</td>\n      <td>0.693578</td>\n      <td>-0.615971</td>\n      <td>-0.847865</td>\n      <td>0.185151</td>\n      <td>-0.043892</td>\n      <td>1</td>\n      <td>STANDING</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 563 columns</p>\n</div>", "text/plain": "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n0           0.288585          -0.020294          -0.132905         -0.995279   \n1           0.278419          -0.016411          -0.123520         -0.998245   \n2           0.279653          -0.019467          -0.113462         -0.995380   \n3           0.279174          -0.026201          -0.123283         -0.996091   \n4           0.276629          -0.016570          -0.115362         -0.998139   \n\n   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n0         -0.983111         -0.913526         -0.995112         -0.983185   \n1         -0.975300         -0.960322         -0.998807         -0.974914   \n2         -0.967187         -0.978944         -0.996520         -0.963668   \n3         -0.983403         -0.990675         -0.997099         -0.982750   \n4         -0.980817         -0.990482         -0.998321         -0.979672   \n\n   tBodyAcc-mad()-Z  tBodyAcc-max()-X    ...     \\\n0         -0.923527         -0.934724    ...      \n1         -0.957686         -0.943068    ...      \n2         -0.977469         -0.938692    ...      \n3         -0.989302         -0.938692    ...      \n4         -0.990441         -0.942469    ...      \n\n   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n0                        -0.710304                    -0.112754   \n1                        -0.861499                     0.053477   \n2                        -0.760104                    -0.118559   \n3                        -0.482845                    -0.036788   \n4                        -0.699205                     0.123320   \n\n   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n0                              0.030400                         -0.464761   \n1                             -0.007435                         -0.732626   \n2                              0.177899                          0.100699   \n3                             -0.012892                          0.640011   \n4                              0.122542                          0.693578   \n\n   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n0                             -0.018446             -0.841247   \n1                              0.703511             -0.844788   \n2                              0.808529             -0.848933   \n3                             -0.485366             -0.848649   \n4                             -0.615971             -0.847865   \n\n   angle(Y,gravityMean)  angle(Z,gravityMean)  subject  Activity  \n0              0.179941             -0.058627        1  STANDING  \n1              0.180289             -0.054317        1  STANDING  \n2              0.180637             -0.049118        1  STANDING  \n3              0.181935             -0.047663        1  STANDING  \n4              0.185151             -0.043892        1  STANDING  \n\n[5 rows x 563 columns]"}, "execution_count": 4, "metadata": {}}], "execution_count": 4}, {"source": "## Data Set 3: Poker Hands Classification\n\n[Poker Hands Classification](https://archive.ics.uci.edu/ml/datasets/Poker+Hand) database from **UCI Machine Learning Repository**.", "cell_type": "markdown", "metadata": {}}, {"source": "-  **Poker Hand Dataset**:   \n     Each record is an example of a hand consisting of five playing\n     cards drawn from a standard deck of 52. Each card is described\n     using two attributes (suit and rank), for a total of 10 predictive\n     attributes. There is one Class attribute that describes the\n     Poker Hand. The order of cards is important, which is why there\n     are 480 possible Royal Flush hands as compared to 4 (one for each\n     suit \u00f1 explained in more detail below).\n     \n\n-  **Training VS Test Dataset**:  \n    Number of Instances: 25010 training, 1,000,000 testing\n\n\n-  **Attribute Information**:\n\n    1) S1 Suit of card #1\n          Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n    2) C1 Rank of card #1\n          Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n    3) S2 Suit of card #2\n          Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n    4) C2 Rank of card #2\n          Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n    5) S3 Suit of card #3\n          Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n    6) C3 Rank of card #3\n          Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n    7) S4 Suit of card #4\n          Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n    8) C4 Rank of card #4\n          Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n    9) S5 Suit of card #5\n          Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}\n\n    10) C5 Rank of card 5\n          Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)\n\n    11) CLASS Poker Hand\n          Ordinal (0-9)\n\n        0: Nothing in hand; not a recognized poker hand  \n        1: One pair; one pair of equal ranks within five cards  \n        2: Two pairs; two pairs of equal ranks within five cards  \n        3: Three of a kind; three equal ranks within five cards  \n        4: Straight; five cards, sequentially ranked with no gaps  \n        5: Flush; five cards with the same suit  \n        6: Full house; pair + different rank three of a kind  \n        7: Four of a kind; four equal ranks within five cards  \n        8: Straight flush; straight + flush  \n        9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush  \n\n\n-  **Class Distribution**:\n\n    The first percentage in parenthesis is the representation\n    within the training set. The second is the probability in the full domain.\n\n    Training set:\n\n        0: Nothing in hand, 12493 instances (49.95202% / 50.117739%)  \n        1: One pair, 10599 instances, (42.37905% / 42.256903%)  \n        2: Two pairs, 1206 instances, (4.82207% / 4.753902%)  \n        3: Three of a kind, 513 instances, (2.05118% / 2.112845%)  \n        4: Straight, 93 instances, (0.37185% / 0.392465%)  \n        5: Flush, 54 instances, (0.21591% / 0.19654%)  \n        6: Full house, 36 instances, (0.14394% / 0.144058%)  \n        7: Four of a kind, 6 instances, (0.02399% / 0.02401%)  \n        8: Straight flush, 5 instances, (0.01999% / 0.001385%)  \n        9: Royal flush, 5 instances, (0.01999% / 0.000154%)  \n\n    The Straight flush and Royal flush hands are not as representative of  \n    the true domain because they have been over-sampled. The Straight flush  \n    is 14.43 times more likely to occur in the training set, while the  \n    Royal flush is 129.82 times more likely.\n\n    Total of 25010 instances in a domain of 311,875,200.\n\n    Testing set:  \n\n        The value inside parenthesis indicates the representation within the test  \n        set as compared to the entire domain. 1.0 would be perfect representation,  \n        while <1.0 are under-represented and >1.0 are over-represented.\n\n        0: Nothing in hand, 501209 instances,(1.000063)  \n        1: One pair, 422498 instances,(0.999832)  \n        2: Two pairs, 47622 instances, (1.001746)  \n        3: Three of a kind, 21121 instances, (0.999647)  \n        4: Straight, 3885 instances, (0.989897)  \n        5: Flush, 1996 instances, (1.015569)  \n        6: Full house, 1424 instances, (0.988491)  \n        7: Four of a kind, 230 instances, (0.957934)  \n        8: Straight flush, 12 instances, (0.866426)  \n        9: Royal flush, 3 instances, (1.948052)  \n\n    Total of one million instances in a domain of 311,875,200.", "cell_type": "markdown", "metadata": {}}, {"source": "### Import Data Set 3", "cell_type": "markdown", "metadata": {}}, {"source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_4c3d0bbe98f64d64949e57243722be60 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='cUXAP-2d5lByEhQdpZVMvA6d29wt1Zg3t92oCuXTGDct',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_4c3d0bbe98f64d64949e57243722be60.get_object(Bucket='workshopteam7-donotdelete-pr-eriuhxku3y6swk',Key='poker-hand-training-true.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>11</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>11</td>\n      <td>2</td>\n      <td>13</td>\n      <td>2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>12</td>\n      <td>3</td>\n      <td>11</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  C\n0   1  10   1  11   1  13   1  12   1    1  9\n1   2  11   2  13   2  10   2  12   2    1  9\n2   3  12   3  11   3  13   3  10   3    1  9\n3   4  10   4  11   4   1   4  13   4   12  9\n4   4   1   4  13   4  12   4  11   4   10  9"}, "execution_count": 5, "metadata": {}}], "execution_count": 5}, {"source": "**=================================================================================================================================================**\n\n### Exploratory Data Analysis", "cell_type": "markdown", "metadata": {}}, {"source": "Before we run into a model on the data, we first shall do the basic **Exploratory Data Analysis** on the dataset.\n\n**Exploratory Data Analysis (EDA)** is an approach/philosophy for data analysis that employs a variety of techniques (mostly graphical) to\n- Maximize insight into a data set;\n- Uncover underlying structure;\n- Extract important variables;\n- Detect outliers and anomalies;\n- Test underlying assumptions;\n- Develop parsimonious models; \n- Determine optimal factor settings.\n\nMost EDA techniques are **graphical** in nature with a few quantitative techniques. The reason for the heavy reliance on graphics is that by its very nature the main role of EDA is to open-mindedly explore, and graphics gives the analysts unparalleled power to reveal its structural secrets, and being always ready to gain some new insight into the data. \n\nThe particular graphical techniques employed in EDA are often quite simple, consisting of various techniques of:\n\n- Plotting the raw data (such as data traces, histograms, bihistograms, probability plots, lag plots, block plots, and Youden plots.\n- Plotting simple statistics such as mean plots, standard deviation plots, box plots, and main effects plots of the raw data.\n- Positioning such plots so as to maximize our natural pattern-recognition abilities, such as using multiple plots per page.", "cell_type": "markdown", "metadata": {}}, {"source": "*Write your code below to perform Exploratory Data Analysis*", "cell_type": "markdown", "metadata": {}}, {"source": "#### Hints: For Exploration on this dataset, you may consider the following questions:\n* What's the characteristics/summary statistics/distribution of the attributes/target?\n* Shall we visualize such distributions of the attributes/target?\n* Is the training data biased towards certain subject? Does each subject contribute to the dataset records on a similar level?\n* ...", "cell_type": "markdown", "metadata": {}}, {"source": "For Data Visualizatin, we may need to use the following code:\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12, 8\n```", "cell_type": "markdown", "metadata": {}}, {"source": "## Summary Statistics\n", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 9}, {"source": "## Graphical Perspective on the Dataset\n", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 10}, {"source": "## ...\n", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 11}, {"source": "### Consider the Goal\nAfter we do the **Exploratory Data Analysis** on the dataset, we get a basic idea on the data flavor.  \nNow, it is time to consider the goal of our project.  \n\n-**For dataset 1:**  \n    **We define the DepDelay > 15 minutes as delay. How to classify whether the flights is delay using the attributes?**  \n\n-**For dataset 2:**  \n    **How to do classification on the six human activities using hundreds of sensor generated attributes?What's the common pattern for human activities? Does there exist clusters in human activities?**\n\n-**For dataset 3:**  \n    **how to do classification on the poker hand classes using hundreds of sensor generated attributes? The intent of this challenge is automatic rules induction, i.e. to learn the rules using machine learning, without hand coding heuristics.**", "cell_type": "markdown", "metadata": {}}, {"source": "*Write your markdown below to tell us what your project goal is?*", "cell_type": "markdown", "metadata": {}}, {"source": "Our team choose the project goal as: \n\nWe consider to use XXXX (write the intended model you want to use) models to hack the problem!\n", "cell_type": "markdown", "metadata": {}}, {"source": "### Modeling Period", "cell_type": "markdown", "metadata": {}}, {"source": "Now we go into modeling period after we have clarified our goal and our detailed study into the dataset.", "cell_type": "markdown", "metadata": {}}, {"source": "For Classification problem, we may need the following, **only for reference, not limited to**:\n```python\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n```\n\n*Write your code below to perform Modeling*", "cell_type": "markdown", "metadata": {}}, {"source": "## write your code here", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 20}, {"source": "## ...", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 21}, {"source": "### Model Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "Let us consider the obvious question, \"How do we estimate the performance of a machine learning model?\"  \n\n\nA typical answer to this question might be as follows: \n- First, we feed the training data to our learning algorithm to learn a model. \n- Second, we predict the labels of our training/test set. \n- Third, we count the number of wrong predictions on the training/test dataset to compute the model\u2019s prediction accuracy.  \n\nFor **Classfication** problems, we shall consider:\n- Classification Accuracy.\n- Loss.\n- Area Under ROC Curve.\n- Confusion Matrix.\n\n*Write your code below to perform Modeling Evaluation*", "cell_type": "markdown", "metadata": {}}, {"source": "## write your code here", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null}, {"source": "## ...", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null}, {"source": "### Further Looking into the Modeling Result ...\n\nThis part is the open part where we could do relavant analysis on the dataset with our own sparkling ideas.  \n- We may want to see what kind of the records are misclassified.\n- We may do whatever other analysis : ) Just try it\uff01\uff01", "cell_type": "markdown", "metadata": {}}, {"source": "## your performance is beyond your imagination!", "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null}, {"source": "## ...", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 7}, {"source": "### Reference\n1. [Flights Dataset](http://stat-computing.org/dataexpo/2009/the-data.html)\n2. [Human Activity Recognition](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)\n3. [Poker Hands Classification](https://archive.ics.uci.edu/ml/datasets/Poker+Hand)\n4. [Model Evaluation](https://sebastianraschka.com/pdf/manuscripts/model-eval.pdf)", "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}